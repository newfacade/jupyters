{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDA\n",
    "\n",
    "```{note}\n",
    "Gaussian Discriminant Analysis(GDA) suppose that observations are presumed to come from one of several multivariate normal distributions.<br/>\n",
    "It is \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution\n",
    "\n",
    "Normal distribution is parameterized by a mean vector $\\mu \\in \\mathbb{R}^{d}$ and a covariance matrix $\\Sigma \\in \\mathbb{R}^{d \\times d}$, where $\\Sigma >= 0$ is symmetric and positive semi-definite, also written $\\mathcal{N}(\\mu,\\Sigma)$, it's density is given by：\n",
    "\n",
    "$$p(x;\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{d/2}\\left | \\Sigma \\right |^{1/2} }\\exp\\left ( -\\frac{1}{2}(x-\\mu)^{T}{\\Sigma}^{-1}(x-\\mu)\\right )$$\n",
    "\n",
    "unsurprisingly, for random variable $X \\sim \\mathcal{N}(\\mu,\\Sigma)$:\n",
    "\n",
    "$$E[X] = \\int_{x}xp(x;\\mu, \\Sigma)dx = \\mu$$\n",
    "$$Cov(X) = E[(X - E(X))(X - E(X))^{T}] = \\Sigma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "When we have a classification problem in which the input features $x$ are continous, we can use GDA, which model $p(x|y)$ using the multivariant normal distribution:\n",
    "\n",
    "$$y\\sim Bernoulli(\\phi)$$\n",
    "$$x | y=0 \\sim \\mathcal{N}(\\mu_{0},\\Sigma) $$\n",
    "$$x | y=1 \\sim \\mathcal{N}(\\mu_{1},\\Sigma) $$\n",
    "\n",
    "density:\n",
    "\n",
    "$$p(y) = \\phi^{y}(1 - \\phi)^{1 - y}$$\n",
    "\n",
    "$$p(x| y=0)=\\frac{1}{(2\\pi)^{d/2}\\left | \\Sigma \\right |^{1/2} }\\exp\\left (-\\frac{1}{2}(x-\\mu_{0})^{T}{\\Sigma}^{-1}(x-\\mu_{0})\\right )$$\n",
    "\n",
    "$$p(x| y=1)=\\frac{1}{(2\\pi)^{d/2}\\left | \\Sigma \\right |^{1/2} }\\exp\\left (-\\frac{1}{2}(x-\\mu_{1})^{T}{\\Sigma}^{-1}(x-\\mu_{1})\\right )$$\n",
    "\n",
    "Then the log-likelihood of the data is given by：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "l(\\phi,\\mu_{0},\\mu_{1},\\Sigma) &= \\log\\prod_{i=1}^{n}p(x^{(i)},y^{(i)};\\phi,\\mu_{0},\\mu_{1},\\Sigma) \\\\\n",
    "&= \\log\\prod_{i=1}^{n}p(x^{(i)}|y^{(i)};\\mu_{0},\\mu_{1},\\Sigma)p(y^{(i)};\\phi)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Maximum Likelihood Estimate result：\n",
    "\n",
    "$$\\phi = \\frac{1}{n}\\sum_{i=1}^{n}1\\left \\{ y^{(i)}=1 \\right \\}$$\n",
    "\n",
    "$$\\mu_{0} = \\frac{\\sum_{i=1}^{n}1\\left \\{ y^{(i)}=0 \\right \\}x^{(i)}  }{\\sum_{i=1}^{n}1\\left \\{ y^{(i)}=0 \\right \\}} $$\n",
    "\n",
    "$$\\mu_{1} = \\frac{\\sum_{i=1}^{n}1\\left \\{ y^{(i)}=1 \\right \\}x^{(i)}  }{\\sum_{i=1}^{n}1\\left \\{ y^{(i)}=1 \\right \\}} $$\n",
    "\n",
    "$$\\Sigma=\\frac{1}{n}\\sum_{i=1}^{n}(x^{(i)} - \\mu_{y^{(i)}})(x^{(i)} - \\mu_{y^{(i)}})^{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
